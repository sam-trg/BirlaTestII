{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtMRXtkhqicJjKbZy1yvv2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sam-trg/BirlaTestII/blob/main/whisper_tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“¦ Install dependencies\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q faster-whisper\n",
        "!apt-get -y install ffmpeg\n",
        "\n",
        "# âš™ï¸ Setup paths\n",
        "input_ogg = \"files/test.ogg\"\n",
        "output_wav = \"files/test_16k.wav\"\n",
        "output_mp3 = \"files/test.mp3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNQV565Js7rs",
        "outputId": "2b1918ad-aac2-45fa-f921-7ba53de2a3c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”§ Audio conversion functions\n",
        "import time\n",
        "import subprocess\n",
        "\n",
        "def convert_ogg_to_wav(input_ogg, output_wav, sample_rate=16000):\n",
        "    start = time.time()\n",
        "    subprocess.run([\n",
        "        \"ffmpeg\", \"-i\", input_ogg,\n",
        "        \"-ar\", str(sample_rate),\n",
        "        \"-ac\", \"1\",\n",
        "        \"-y\", output_wav\n",
        "    ], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    return time.time() - start\n",
        "\n",
        "def convert_ogg_to_mp3(input_ogg, output_mp3):\n",
        "    start = time.time()\n",
        "    subprocess.run([\"ffmpeg\", \"-i\", input_ogg, \"-acodec\", \"libmp3lame\", \"-q:a\", \"4\", output_mp3], check=True)\n",
        "    return time.time() - start"
      ],
      "metadata": {
        "id": "1exs5HfotCqx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¤ Transcription functions\n",
        "import whisper\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "def transcribe_with_whisper(input_audio, model_type=\"base\"):\n",
        "    model = whisper.load_model(model_type)\n",
        "    start = time.time()\n",
        "    result = model.transcribe(input_audio)\n",
        "    return time.time() - start, result[\"text\"]\n",
        "\n",
        "def transcribe_with_faster_whisper(input_audio, model_type=\"base\", device=\"cpu\"):\n",
        "    model = WhisperModel(model_type, device=device, compute_type=\"int8\")\n",
        "    start = time.time()\n",
        "    segments, _ = model.transcribe(input_audio, beam_size=5)\n",
        "    text = \" \".join([segment.text for segment in segments])\n",
        "    return time.time() - start, text"
      ],
      "metadata": {
        "id": "aS8Ml93ftJmf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§ª Benchmark 1: Direct OGG input\n",
        "print(\"=== Direct OGG Input ===\")\n",
        "time_vanilla, text_vanilla = transcribe_with_whisper(input_ogg)\n",
        "print(f\"Vanilla Whisper: {time_vanilla:.2f}s\\n{text_vanilla}\\n\")\n",
        "\n",
        "time_faster, text_faster = transcribe_with_faster_whisper(input_ogg)\n",
        "print(f\"Faster Whisper: {time_faster:.2f}s\\n{text_faster}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAYr92O3tMCy",
        "outputId": "cbbf0b91-b05d-496b-d247-4a77bed2adb7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Direct OGG Input ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla Whisper: 6.27s\n",
            " Ù…Ø¬Ú¾Û’ Ø¯Ù„ÛŒ Ù…ÛŒÚº Ø¯Ú©Ù¹Ø±Ø³ Ø¯Ú©Ú¾Ø§ÛŒØ§\n",
            "\n",
            "Faster Whisper: 5.20s\n",
            " Ù…Ø¬Ú¾Û’ Ø¯Ù„ÛŒ Ù…ÛŒÚº Ø¯Ú©Ù¹Ø±Ø³ Ø¯ÛŒÚ©Ú¾Ø§ÛŒØ§\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“Š Compare result from Benchmark 1\n",
        "similarity = 100 * sum(c1 == c2 for c1, c2 in zip(text_vanilla, text_faster)) / max(len(text_vanilla), len(text_faster))\n",
        "print(f\"Text similarity: {similarity:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEpnI_katO5J",
        "outputId": "c6a7d317-1f23-48bd-cd43-9d260fbe899a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text similarity: 77.8%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§ª Benchmark 2: Convert to MP3 first\n",
        "convert_time = convert_ogg_to_mp3(input_ogg, output_mp3)\n",
        "print(f\"OGG â†’ MP3: {convert_time:.2f}s\")\n",
        "\n",
        "time_vanilla, text_vanilla = transcribe_with_whisper(output_mp3)\n",
        "print(f\"Vanilla Whisper: {time_vanilla:.2f}s\\n{text_vanilla}\\n\")\n",
        "\n",
        "time_faster, text_faster = transcribe_with_faster_whisper(output_mp3)\n",
        "print(f\"Faster Whisper: {time_faster:.2f}s\\n{text_faster}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48HbdlcltRSr",
        "outputId": "289683d5-a02d-4854-9573-6e08f8570e89"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OGG â†’ MP3: 0.20s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla Whisper: 6.14s\n",
            " Ù…Ø¬Ú¾Û’ Ø¯Ù„ÛŒ Ù…ÛŒÚº Ø¯Ú©Ù¹Ø±Ø³ Ø¯Ú©Ú¾Ø§ÛŒØ§\n",
            "\n",
            "Faster Whisper: 4.98s\n",
            " Ù…Ø¬Ú¾Û’ Ø¯Ù„ÛŒ Ù…ÛŒÚº Ø¯Ú©Ù¹Ø±Ø³ Ø¯ÛŒÚ©Ú¾Ø§ÛŒØ§\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“Š Compare result from Benchmark 2\n",
        "similarity = 100 * sum(c1 == c2 for c1, c2 in zip(text_vanilla, text_faster)) / max(len(text_vanilla), len(text_faster))\n",
        "print(f\"Text similarity: {similarity:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiwpvmBItTic",
        "outputId": "a8ca9d8d-5ad4-44e3-d495-a2c956ab5bb1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text similarity: 77.8%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§ª Benchmark 3: Convert to 16kHz WAV\n",
        "convert_time = convert_ogg_to_wav(input_ogg, output_wav)\n",
        "print(f\"OGG â†’ 16kHz WAV: {convert_time:.2f}s\")\n",
        "\n",
        "time_vanilla, text_vanilla = transcribe_with_whisper(output_wav)\n",
        "print(f\"Vanilla Whisper: {time_vanilla:.2f}s\\n{text_vanilla}\\n\")\n",
        "\n",
        "time_faster, text_faster = transcribe_with_faster_whisper(output_wav)\n",
        "print(f\"Faster Whisper: {time_faster:.2f}s\\n{text_faster}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjOFEOfRtWeP",
        "outputId": "c79ea84a-12ef-4cd9-8492-5d87fd99792b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OGG â†’ 16kHz WAV: 0.12s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla Whisper: 6.65s\n",
            " Ù…Ø¬Ú¾Û’ Ø¯Ù„ÛŒ Ù…ÛŒÚº Ø¯Ú©Ù¹Ø±Ø³ Ø¯Ú©Ú¾Ø§ÛŒØ§\n",
            "\n",
            "Faster Whisper: 5.04s\n",
            " Ù…Ø¬Ú¾Û’ Ø¯Ù„ÛŒ Ù…ÛŒÚº Ø¯Ú©Ù¹Ø±Ø³ Ø¯ÛŒÚ©Ú¾Ø§ÛŒØ§\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“Š Compare result from Benchmark 3\n",
        "similarity = 100 * sum(c1 == c2 for c1, c2 in zip(text_vanilla, text_faster)) / max(len(text_vanilla), len(text_faster))\n",
        "print(f\"Text similarity: {similarity:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlnVdhUHtZPB",
        "outputId": "b7a4bf6f-cb0e-40ee-dc7e-af35a4920069"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text similarity: 77.8%\n"
          ]
        }
      ]
    }
  ]
}